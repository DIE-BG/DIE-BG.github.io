---
title: Ejercicio de evaluación de capacidad predictiva para el SVAR50 4B
subtitle: Primera fecha de estimación fija y fecha final de estimación móvil
lang: es
format: 
    revealjs:
        smaller: true
        progress: true
        controls: true
        controls-back-arrows: faded
---

# Introducción

Los experimentos en esta sección investigan **cómo varía la estimación del poder predictivo**, calculado mediante ejercicios consecutivos de evaluación dentro y fuera de muestra (en formato de pronóstico), **a medida que se incorporan nuevas estimaciones con submuestras más extensas y actualizadas.**


# Metodología

Para cada experimento se realizan múltiples ejercicios de evaluación.
Esto significa que se "corre" la HEFM varias veces, y en cada "corrimiento" se agrega una nueva estimación con datos más actualizados y se vuelve a evaluar el poder predictivo del modelo.

Se llevan a cabo tres experimentos:

1. La muestra de validación cambia en cada ejercicio de evaluación, utilizando toda la información disponible y excluyendo las observaciones de la muestra de estimación.

2. Todos los ejercicios de evaluación utilizan la misma muestra de validación, también excluyendo las observaciones de la muestra de estimación.

3. La muestra de validación cambia en cada ejercicio de evaluación, pero en este caso está incluida dentro de la muestra de estimación.

---

::: {.callout-note title="Ejercicio de evaluación"}
Definido como un "corrimiento" de la HEFM, ya sea dentro o fuera de muestra.
:::

::: {.callout-note title="Experimento"}
Conjunto de ejercicios de evaluación, donde cada uno incorpora una nueva estimación con datos más actualizados que el ejercicio anterior.
:::

---

## Descripción del experimento No. 1

En el primer experimento, los ejercicios de evaluación se definen de la siguiente manera: 

- Corrimiento de la HEFM No. 1  
  - Estimaciones incluidas (17 estimaciones): 2005Q1 - 2014Q4, 2005Q1 - 2015Q1, ..., 2005Q1 - 2018Q4

- Corrimiento de la HEFM No. 2  
  - Estimaciones incluidas (18 estimaciones): 2005Q1 - 2014Q4, 2005Q1 - 2015Q1, ..., 2005Q1 - 2019Q1

- ...

- Corrimiento de la HEFM No. 13  
  - Estimaciones incluidas (29 estimaciones): 2005Q1 - 2014Q4, 2005Q1 - 2015Q1, ..., 2005Q1 - 2021Q4

---

## Descripción del experimento No. 2

El segundo experimento es una variante del primero, en el que se restringe la muestra de validación para que sea la misma en todos los ejercicios de evaluación.

- Corrimiento de la HEFM No. 1  
  - Estimaciones incluidas (17 estimaciones): 2005Q1 - 2014Q4, 2005Q1 - 2015Q1, ..., 2005Q1 - 2018Q4  
  - Muestra de validación: 2022Q1 - 2024Q4

- ...

- Corrimiento de la HEFM No. 13  
  - Estimaciones incluidas (29 estimaciones): 2005Q1 - 2014Q4, 2005Q1 - 2015Q1, ..., 2005Q1 - 2021Q4
  - Muestra de validación: 2022Q1 - 2024Q4

---

## Descripción del experimento No. 3

El tercer experimento es una variante del primero, en el que la muestra de validación se encuentra contenida en la muestra de estimación.

- Corrimiento de la HEFM No. 1  
  - Estimaciones incluidas (17 estimaciones): 2005Q1 - 2014Q4, 2005Q1 - 2015Q1, ..., 2005Q1 - 2018Q4  
  - Muestras de validación: La misma que la de estimación.

- ...

- Corrimiento de la HEFM No. 13
  - Estimaciones incluidas (29 estimaciones): 2005Q1 - 2014Q4, 2005Q1 - 2015Q1, ..., 2005Q1 - 2021Q4  
  - Muestras de validación: La misma que la de estimación.

# Resultados

---

## Experimento No. 1

En este experimento, el RMSE promedio de las variables objetivo disminuye al agregar consecutivamente estimaciones del modelo con submuestras más amplias y actualizadas (@fig-avg).
Al aumentar el horizonte de pronóstico evaluado, el RMSE promedio se invierte, pasando de mostrar una caída constante a lo largo de los ejercicios de evaluación a adoptar una forma de "U".

La @fig-perVar muestra el RMSE de las variables que componen el promedio en la @fig-avg.
En general, el RMSE de estas variables aumenta al incorporar consecutivamente nuevas estimaciones con submuestras más amplias y actualizadas.

El ritmo al que crece el RMSE varía entre las distintas variables, siendo notable el caso de `d4_ln_y_sm`, cuyo RMSE disminuye en los ejercicios con menos submuestras de estimación y aumenta a partir de aquellos que incluyen submuestras de estimación con datos del período de COVID-19.

---

![Promedio de las variables objetivo a diferentes horizontes para el experimento  No. 1](images/average_loss.png){#fig-avg}

---

![Variables objetivo a diferentes horizontes para el experimento No. 1](images/average_loss_per_var.png){width=100% #fig-perVar}

---

## Experimento No. 2

Al fijar la muestra de validación en todos los ejercicios de evaluación, se observa que el promedio de los RMSE de las variables objetivo disminuye en los horizontes cortos a medida que se agregan submuestras de estimación más extensas y actualizadas, pero esta tendencia se invierte conforme aumenta el horizonte de pronóstico (@fig-avgSameSample). Este resultado es similar al encontrado en el experimento No. 1.

Al observar el resultado por variable objetivo (@fig-perVarSameSample), los resultados son similares a los del experimento No. 1, destacando nuevamente el comportamiento de `d4_ln_y_sm`, cuyo RMSE disminuye en los ejercicios con menos submuestras de estimación y aumenta a partir de aquellos que incluyen submuestras con datos del período de COVID-19.

---

![Promedio de las variables objetivo a diferentes horizontes para el experimento  No. 2](images/average_loss_sameValidationSet.png){#fig-avgSameSample}

---

![Variables objetivo a diferentes horizontes para el experimento No. 2](images/average_loss_per_var_sameValidationSet.png){#fig-perVarSameSample}

---

## Experimento 3

Al evaluar dentro de la muestra, el incremento en el número de submuestras de estimación perjudica, en general, el resultado del RMSE (@fig-avgIS y @fig-perVarIS), siendo consistente con los experimentos No. 1 y No. 2.

---

![Promedio de las variables objetivo a diferentes horizontes para el experimento  No. 3](images/average_loss_IS.png){#fig-avgIS}

---

![Variables objetivo a diferentes horizontes para el experimento No. 3](images/average_loss_per_var_IS.png){#fig-perVarIS}


---

## Comparación entre experimentos

En las siguientes gráficas se muestra el resultados de los tres experimentos simultáneamente.

- <span style="display:inline-block;width:12px;height:12px;background-color:#0072BD;margin-right:8px;border-radius:2px;"></span> Experimento 1 (OS)
- <span style="display:inline-block;width:12px;height:12px;background-color:#D95319;margin-right:8px;border-radius:2px;"></span> Experimento 2 (OS mismo conjunto de validación)
- <span style="display:inline-block;width:12px;height:12px;background-color:#EDB120;margin-right:8px;border-radius:2px;"></span> Experimento 3 (IS)

---

![](images/average_loss_comparative.png){#fig-avg-comp}

<span style="display:inline-block;width:12px;height:12px;background-color:#0072BD;margin-right:8px;border-radius:2px;"></span> <span style="font-size:0.75rem;">Experimento 1</span>
<span style="display:inline-block;width:12px;height:12px;background-color:#D95319;margin-right:8px;border-radius:2px;"></span> <span style="font-size:0.75rem;">Experimento 2</span>
<span style="display:inline-block;width:12px;height:12px;background-color:#EDB120;margin-right:8px;border-radius:2px;"></span> <span style="font-size:0.75rem;">Experimento 3</span>

---

![](images/average_loss_per_var_comparative.png){width=100% #fig-perVar-comp}

<span style="display:inline-block;width:12px;height:12px;background-color:#0072BD;margin-right:8px;border-radius:2px;"></span> <span style="font-size:0.75rem;">Experimento 1</span>
<span style="display:inline-block;width:12px;height:12px;background-color:#D95319;margin-right:8px;border-radius:2px;"></span> <span style="font-size:0.75rem;">Experimento 2</span>
<span style="display:inline-block;width:12px;height:12px;background-color:#EDB120;margin-right:8px;border-radius:2px;"></span> <span style="font-size:0.75rem;">Experimento 3</span>
---


## Conclusiones

Para un modelo con un procedimiento de estimación que logra capturar la dinámica conjunta de los datos, y asumiendo que dicha dinámica se mantiene a lo largo del tiempo, se espera que el error de pronóstico a un mismo horizonte disminuya al incrementar el tamaño de las submuestras de estimación incluidas en cada ejercicio de evaluación.

Los resultados muestran que el RMSE tiende a incrementarse al añadir nuevas estimaciones con submuestras más grandes y actualizadas, lo que sugiere que esta combinación de modelo y procedimiento de estimación no es capaz de mejorar su poder predictivo al actualizar e incrementar la muestra de estimación.